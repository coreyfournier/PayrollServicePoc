version: '3.8'

services:
  # Zookeeper for Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    networks:
      - payroll-network
    healthcheck:
      test: echo srvr | nc localhost 2181 || exit 1
      interval: 10s
      timeout: 5s
      retries: 5

  # Kafka message broker
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    networks:
      - payroll-network
    healthcheck:
      test: kafka-broker-api-versions --bootstrap-server localhost:9092 || exit 1
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 30s

  # MongoDB database (replica set for transaction support)
  mongodb:
    image: mongo:7.0
    container_name: mongodb
    command: ["--replSet", "rs0", "--bind_ip_all"]
    ports:
      - "27017:27017"
    volumes:
      - mongodb_data:/data/db
    networks:
      - payroll-network
    healthcheck:
      test: |
        mongosh --eval '
          try {
            rs.status().ok
          } catch(e) {
            rs.initiate({_id: "rs0", members: [{_id: 0, host: "mongodb:27017"}]});
            sleep(1000);
            rs.status().ok
          }
        ' --quiet || exit 1
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 15s

  # MySQL database
  mysql:
    image: mysql:8.0
    container_name: mysql
    ports:
      - "3306:3306"
    environment:
      MYSQL_ROOT_PASSWORD: root_password
      MYSQL_DATABASE: listener_db
      MYSQL_USER: listener_user
      MYSQL_PASSWORD: listener_password
    volumes:
      - mysql_data:/var/lib/mysql
    networks:
      - payroll-network
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "root", "-proot_password"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # Keycloak database (PostgreSQL)
  keycloak-db:
    image: postgres:16-alpine
    container_name: keycloak-db
    environment:
      POSTGRES_DB: keycloak
      POSTGRES_USER: keycloak
      POSTGRES_PASSWORD: keycloak_password
    volumes:
      - keycloak_db_data:/var/lib/postgresql/data
    networks:
      - payroll-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U keycloak"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Keycloak identity provider
  keycloak:
    image: quay.io/keycloak/keycloak:24.0
    container_name: keycloak
    command: start-dev --import-realm
    environment:
      KC_DB: postgres
      KC_DB_URL: jdbc:postgresql://keycloak-db:5432/keycloak
      KC_DB_USERNAME: keycloak
      KC_DB_PASSWORD: keycloak_password
      KEYCLOAK_ADMIN: admin
      KEYCLOAK_ADMIN_PASSWORD: admin
      KC_HEALTH_ENABLED: "true"
      KC_HTTP_PORT: 8180
      KC_HOSTNAME_URL: http://localhost:8180
      KC_HOSTNAME_STRICT: "false"
      KC_HOSTNAME_STRICT_HTTPS: "false"
    ports:
      - "8180:8180"
    volumes:
      - ./keycloak:/opt/keycloak/data/import
    depends_on:
      keycloak-db:
        condition: service_healthy
    networks:
      - payroll-network
    healthcheck:
      test: ["CMD-SHELL", "exec 3<>/dev/tcp/localhost/8180 && echo -e 'GET /health/ready HTTP/1.1\\r\\nHost: localhost\\r\\nConnection: close\\r\\n\\r\\n' >&3 && cat <&3 | grep -q '200 OK'"]
      interval: 15s
      timeout: 10s
      retries: 15
      start_period: 60s

  # Zipkin for distributed tracing
  zipkin:
    image: openzipkin/zipkin:latest
    container_name: zipkin
    ports:
      - "9411:9411"
    networks:
      - payroll-network

  # ksqlDB server for stream processing
  ksqldb-server:
    image: confluentinc/cp-ksqldb-server:7.7.1
    container_name: ksqldb-server
    ports:
      - "8088:8088"
    environment:
      KSQL_BOOTSTRAP_SERVERS: kafka:9092
      KSQL_LISTENERS: http://0.0.0.0:8088/
      KSQL_KSQL_SERVICE_ID: payroll_ksqldb_
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_NAME: KSQL_PROCESSING_LOG
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - payroll-network

  # Net Pay Processor — Kafka Streams app computing net pay from gross pay, taxes, and deductions
  net-pay-processor:
    build:
      context: ./src/NetPayProcessor
      dockerfile: Dockerfile
    container_name: net-pay-processor
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      APPLICATION_ID: net-pay-processor
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - payroll-network
    restart: on-failure

  # Elasticsearch for search
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.12.0
    container_name: elasticsearch
    ports:
      - "9200:9200"
    environment:
      discovery.type: single-node
      xpack.security.enabled: "false"
      ES_JAVA_OPTS: "-Xms512m -Xmx512m"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    networks:
      - payroll-network
    healthcheck:
      test: curl -sf http://localhost:9200/_cluster/health || exit 1
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s

  # Kafka Connect with Elasticsearch Sink Connector
  kafka-connect:
    build:
      context: ./docker
      dockerfile: Dockerfile.kafka-connect
    container_name: kafka-connect
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka:9092
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: payroll-connect
      CONNECT_CONFIG_STORAGE_TOPIC: _connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: _connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: _connect-status
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_REST_ADVERTISED_HOST_NAME: kafka-connect
      CONNECT_PLUGIN_PATH: /usr/share/java,/usr/share/confluent-hub-components
    depends_on:
      kafka:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
    networks:
      - payroll-network
    healthcheck:
      test: curl -sf http://localhost:8083/connectors || exit 1
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s

  # Elasticsearch Updater — combines employee-info + employee-net-pay → employee-search topic
  elasticsearch-updater:
    build:
      context: ./src/ElasticsearchUpdater
      dockerfile: Dockerfile
    container_name: elasticsearch-updater
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      APPLICATION_ID: elasticsearch-updater
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - payroll-network
    restart: on-failure

  # Kafka UI for monitoring
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: payroll-cluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
      KAFKA_CLUSTERS_0_KSQLDBSERVER: http://ksqldb-server:8088
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_NAME: payroll-connect
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_ADDRESS: http://kafka-connect:8083
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - payroll-network

  # Payroll API Service
  payroll-api:
    build:
      context: .
      dockerfile: docker/Dockerfile
    container_name: payroll-api
    ports:
      - "5000:80"
    environment:
      - ASPNETCORE_ENVIRONMENT=Development
      - ASPNETCORE_URLS=http://+:80
      - MongoDB__ConnectionString=mongodb://mongodb:27017/?replicaSet=rs0
      - MongoDB__DatabaseName=payroll_db
      - Features__UseDaprOutbox=true
      # Dapr sidecar endpoint configuration
      - DAPR_HTTP_ENDPOINT=http://payroll-api-dapr:3500
      - DAPR_GRPC_ENDPOINT=http://payroll-api-dapr:50001
      # Keycloak JWT authentication
      - Keycloak__Authority=http://keycloak:8180/realms/payroll-pro
      - Keycloak__Audience=payroll-api
      - Features__UseKeycloakAuth=${USE_KEYCLOAK_AUTH:-true}
    depends_on:
      mongodb:
        condition: service_healthy
      kafka:
        condition: service_healthy
    networks:
      - payroll-network
    healthcheck:
      test: curl -sf http://localhost:80/swagger/v1/swagger.json || exit 1
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 20s

  # Dapr sidecar for Payroll API
  payroll-api-dapr:
    image: "daprio/daprd:1.16.0"
    container_name: payroll-api-dapr
    command: [
      "./daprd",
      "-app-id", "payroll-api",
      "-app-port", "80",
      "-app-channel-address", "payroll-api",
      "-dapr-http-port", "3500",
      "-dapr-grpc-port", "50001",
      "-resources-path", "/components",
      "-config", "/config/config.yaml"
    ]
    ports:
      - "3500:3500"   # Dapr HTTP port
      - "50001:50001" # Dapr gRPC port
    volumes:
      - ./dapr/components:/components
      - ./dapr:/config
    depends_on:
      payroll-api:
        condition: service_healthy
      kafka:
        condition: service_healthy
      mongodb:
        condition: service_healthy
    networks:
      - payroll-network
    restart: on-failure

  # Frontend Application
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        VITE_AUTH_ENABLED: ${VITE_AUTH_ENABLED:-true}
    container_name: payroll-frontend
    ports:
      - "3000:80"
    depends_on:
      payroll-api:
        condition: service_healthy
    networks:
      - payroll-network

  # ListenerApi Service
  listener-api:
    build:
      context: .
      dockerfile: docker/Dockerfile.listenerapi
    container_name: listener-api
    ports:
      - "5001:80"
    environment:
      - ASPNETCORE_ENVIRONMENT=Development
      - ASPNETCORE_URLS=http://+:80
      - ConnectionStrings__DefaultConnection=Server=mysql;Database=listener_db;User=listener_user;Password=listener_password;
      # Dapr sidecar endpoint configuration
      - DAPR_HTTP_ENDPOINT=http://listener-api-dapr:3501
      - DAPR_GRPC_ENDPOINT=http://listener-api-dapr:50002
      # Keycloak JWT authentication
      - Keycloak__Authority=http://keycloak:8180/realms/listener-client
      - Keycloak__Audience=listener-api
      - Features__UseKeycloakAuth=${USE_KEYCLOAK_AUTH:-true}
    depends_on:
      mysql:
        condition: service_healthy
      kafka:
        condition: service_healthy
    networks:
      - payroll-network
    healthcheck:
      test: curl -sf http://localhost:80/health || exit 1
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 30s

  # Dapr sidecar for ListenerApi
  listener-api-dapr:
    image: "daprio/daprd:1.16.0"
    container_name: listener-api-dapr
    command: [
      "./daprd",
      "-app-id", "listener-api",
      "-app-port", "80",
      "-app-channel-address", "listener-api",
      "-dapr-http-port", "3501",
      "-dapr-grpc-port", "50002",
      "-resources-path", "/components",
      "-config", "/config/config.yaml"
    ]
    volumes:
      - ./dapr/components:/components
      - ./dapr:/config
    depends_on:
      listener-api:
        condition: service_healthy
      kafka:
        condition: service_healthy
    networks:
      - payroll-network
    restart: on-failure

  # ListenerClient Frontend
  listener-client:
    build:
      context: ./listenerClient
      dockerfile: Dockerfile
      args:
        VITE_AUTH_ENABLED: ${VITE_AUTH_ENABLED:-true}
    container_name: listener-client
    ports:
      - "3001:80"
    depends_on:
      listener-api:
        condition: service_healthy
    networks:
      - payroll-network

  # Seed script — run with: docker-compose up seed
  seed:
    image: confluentinc/cp-kafka:7.5.0
    container_name: seed
    environment:
      - USE_KEYCLOAK_AUTH=${USE_KEYCLOAK_AUTH:-true}
    depends_on:
      payroll-api:
        condition: service_healthy
      listener-api:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
      kafka-connect:
        condition: service_healthy
    volumes:
      - ./scripts/seed.sh:/seed.sh
      - ./ksqldb/statements.sql:/statements.sql
    entrypoint: ["bash", "/seed.sh"]
    networks:
      - payroll-network

networks:
  payroll-network:
    driver: bridge

volumes:
  mongodb_data:
  mysql_data:
  elasticsearch_data:
  keycloak_db_data:
